<!DOCTYPE html><html lang="en" data-astro-cid-37fxchfa> <head><meta charset="UTF-8"><meta name="description" property="og:description" content="This project showcases a unique implementation of the Transformer architecture, inspired by the &#34;Attention is All You Need&#34; paper and Andrej Karpathy's tutorial series.
"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Astro v4.12.3"><title>nanoGPT x Friends</title><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Public+Sans:ital,wght@0,400;0,700;1,400&family=Rubik:wght@500;600&display=swap" rel="stylesheet"><script>
	// This code is inlined in the head to make dark mode instant & blocking.
	const getThemePreference = () => {
		// Check localStorage for the theme preference
		if (typeof localStorage !== 'undefined' && localStorage.getItem('theme')) {
			return localStorage.getItem('theme');
		}
		return 'dark'; // Default to dark mode if no preference is found
	};

	const setTheme = (theme) => {
		document.documentElement.classList[theme === 'dark' ? 'add' : 'remove']('theme-dark');
		if (typeof localStorage !== 'undefined') {
			localStorage.setItem('theme', theme);
		}
	};

	const theme = getThemePreference();
	setTheme(theme);

	if (typeof localStorage !== 'undefined') {
		// Watch the document element and persist user preference when it changes.
		const observer = new MutationObserver(() => {
			const isDark = document.documentElement.classList.contains('theme-dark');
			localStorage.setItem('theme', isDark ? 'dark' : 'light');
		});
		observer.observe(document.documentElement, { attributes: true, attributeFilter: ['class'] });
	}
</script><link rel="stylesheet" href="/_astro/about.Ccmr6cc3.css">
<style>a[data-astro-cid-balv45lp]{position:relative;display:flex;place-content:center;text-align:center;padding:.56em 2em;gap:.8em;color:var(--accent-text-over);text-decoration:none;line-height:1.1;border-radius:999rem;overflow:hidden;background:var(--gradient-accent-orange);box-shadow:var(--shadow-md);white-space:nowrap}@media (min-width: 20em){a[data-astro-cid-balv45lp]{font-size:var(--text-lg)}}a[data-astro-cid-balv45lp]:after{content:"";position:absolute;inset:0;pointer-events:none;transition:background-color var(--theme-transition);mix-blend-mode:overlay}a[data-astro-cid-balv45lp]:focus:after,a[data-astro-cid-balv45lp]:hover:after{background-color:hsla(var(--gray-999-basis),.3)}@media (min-width: 50em){a[data-astro-cid-balv45lp]{padding:1.125rem 2.5rem;font-size:var(--text-xl)}}aside[data-astro-cid-rcdzuq3a]{display:flex;flex-direction:column;align-items:center;gap:3rem;border-top:1px solid var(--gray-800);border-bottom:1px solid var(--gray-800);padding:5rem 1.5rem;background-color:var(--gray-999_40);box-shadow:var(--shadow-sm)}h2[data-astro-cid-rcdzuq3a]{font-size:var(--text-xl);text-align:center;max-width:15ch}@media (min-width: 50em){aside[data-astro-cid-rcdzuq3a]{padding:7.5rem;flex-direction:row;flex-wrap:wrap;justify-content:space-between}h2[data-astro-cid-rcdzuq3a]{font-size:var(--text-3xl);text-align:left}}
svg[data-astro-cid-patnjmll]{vertical-align:middle;width:var(--size, 1em);height:var(--size, 1em)}
.pill[data-astro-cid-2qeywk4b]{display:flex;padding:.5rem 1rem;gap:.5rem;color:var(--accent-text-over);border:1px solid var(--accent-regular);background-color:var(--accent-regular);border-radius:999rem;font-size:var(--text-md);line-height:1.35;white-space:nowrap}
.github-card[data-astro-cid-cmjzrqcb]{background-color:#0d1117;border:1px solid #30363d;border-radius:6px;padding:16px;margin-top:20px;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,"Apple Color Emoji","Segoe UI Emoji"}.header[data-astro-cid-cmjzrqcb]{display:flex;align-items:center;margin-bottom:8px}.avatar[data-astro-cid-cmjzrqcb]{width:32px;height:32px;border-radius:50%;margin-right:8px}h3[data-astro-cid-cmjzrqcb]{color:#58a6ff;font-size:18px;margin:0}h3[data-astro-cid-cmjzrqcb] a[data-astro-cid-cmjzrqcb]{text-decoration:none;color:inherit}h3[data-astro-cid-cmjzrqcb] a[data-astro-cid-cmjzrqcb]:hover{text-decoration:underline}.description[data-astro-cid-cmjzrqcb]{color:#c9d1d9;font-size:14px;margin-bottom:16px}.stats[data-astro-cid-cmjzrqcb]{display:flex;justify-content:space-between;margin-bottom:8px}.stat[data-astro-cid-cmjzrqcb]{display:flex;align-items:center;color:#8b949e;font-size:12px}.stat-icon[data-astro-cid-cmjzrqcb]{margin-right:4px}.language[data-astro-cid-cmjzrqcb]{display:flex;align-items:center;color:#8b949e;font-size:12px}.language-dot[data-astro-cid-cmjzrqcb]{width:12px;height:12px;border-radius:50%;margin-right:4px}header[data-astro-cid-qwekciqp]{padding-bottom:2.5rem;border-bottom:1px solid var(--gray-800)}.project-info[data-astro-cid-qwekciqp]{display:flex;flex-direction:column;gap:1.5rem}.left-column[data-astro-cid-qwekciqp],.right-column[data-astro-cid-qwekciqp]{flex:1}.back-link[data-astro-cid-qwekciqp]{display:none}.details[data-astro-cid-qwekciqp]{display:flex;flex-direction:column;padding:.5rem;gap:1.5rem;justify-content:space-between;align-items:center}.tags[data-astro-cid-qwekciqp]{display:flex;gap:.5rem}.description[data-astro-cid-qwekciqp]{font-size:var(--text-lg);max-width:54ch}.content[data-astro-cid-qwekciqp]{width:90%;margin-inline:auto;text-align:justify}.content[data-astro-cid-qwekciqp]>*+*{margin-top:1rem}.content[data-astro-cid-qwekciqp] h1,.content[data-astro-cid-qwekciqp] h2,.content[data-astro-cid-qwekciqp] h3,.content[data-astro-cid-qwekciqp] h4,.content[data-astro-cid-qwekciqp] h5{margin:1.5rem 0}.content[data-astro-cid-qwekciqp] img{border-radius:1.5rem;box-shadow:var(--shadow-sm);background:var(--gradient-subtle);border:1px solid var(--gray-800)}.content[data-astro-cid-qwekciqp] blockquote{font-size:var(--text-lg);font-family:var(--font-brand);font-weight:600;line-height:1.1;padding-inline-start:1.5rem;border-inline-start:.25rem solid var(--accent-dark);color:var(--gray-0)}.back-link[data-astro-cid-qwekciqp],.content[data-astro-cid-qwekciqp] a{text-decoration:1px solid underline transparent;text-underline-offset:.25em;transition:text-decoration-color var(--theme-transition)}.back-link[data-astro-cid-qwekciqp]:hover,.back-link[data-astro-cid-qwekciqp]:focus,.content[data-astro-cid-qwekciqp] a:hover,.content[data-astro-cid-qwekciqp] a:focus{text-decoration-color:currentColor}@media (min-width: 50em){.back-link[data-astro-cid-qwekciqp]{display:block;align-self:flex-start}.details[data-astro-cid-qwekciqp]{flex-direction:row;gap:2.5rem}.project-info[data-astro-cid-qwekciqp]{flex-direction:row}.content[data-astro-cid-qwekciqp] blockquote{font-size:var(--text-2xl)}}
</style><script type="module" src="/_astro/hoisted.Bl07r5t7.js"></script></head> <body data-astro-cid-37fxchfa> <div class="stack backgrounds" data-astro-cid-37fxchfa> <nav data-astro-cid-dmqpwcec> <meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"> <div class="menu-header" data-astro-cid-dmqpwcec> <a href="/" class="site-title" data-astro-cid-dmqpwcec> <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="url(#icon-gradient-2mfv8td69)" fill="url(#icon-gradient-2mfv8td69)" style="--size:1.6em" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="m80 96 40 32-40 32m56 0h40"/><rect width="192" height="160" x="32" y="48" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16.97" rx="8.5"/></g> <linearGradient id="icon-gradient-2mfv8td69" x1="23" x2="235" y1="43" y2="202" gradientUnits="userSpaceOnUse" data-astro-cid-patnjmll> <stop stop-color="var(--gradient-stop-1)" data-astro-cid-patnjmll></stop> <stop offset=".5" stop-color="var(--gradient-stop-2)" data-astro-cid-patnjmll></stop> <stop offset="1" stop-color="var(--gradient-stop-3)" data-astro-cid-patnjmll></stop> </linearGradient> </svg> 
Ignacio Correcher
</a> <menu-button data-astro-cid-dmqpwcec> <template data-astro-cid-dmqpwcec> <button class="menu-button" aria-expanded="false" data-astro-cid-dmqpwcec> <span class="sr-only" data-astro-cid-dmqpwcec>Menu</span> <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><path stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M40 128h176M40 64h176M40 192h176"/></g>  </svg>  </button> </template> </menu-button> </div> <noscript> <ul class="nav-items" data-astro-cid-dmqpwcec> <li data-astro-cid-dmqpwcec> <a class="link" href="/" data-astro-cid-dmqpwcec> Home </a> </li><li data-astro-cid-dmqpwcec> <a class="link active" href="/work/" data-astro-cid-dmqpwcec> Work </a> </li><li data-astro-cid-dmqpwcec> <a class="link" href="/about/" data-astro-cid-dmqpwcec> About </a> </li> </ul> </noscript> <noscript> <div class="menu-footer" data-astro-cid-dmqpwcec> <div class="socials" data-astro-cid-dmqpwcec> <a href="https://twitter.com/ignacorrecher" class="social" target="_blank" rel="noopener noreferrer" data-astro-cid-dmqpwcec> <span class="sr-only" data-astro-cid-dmqpwcec>Twitter</span> <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M128 88c0-22 18.5-40.3 40.5-40a40 40 0 0 1 36.2 24H240l-32.3 32.3A127.9 127.9 0 0 1 80 224c-32 0-40-12-40-12s32-12 48-36c0 0-64-32-48-120 0 0 40 40 88 48Z"/></g>  </svg>  </a><a href="https://github.com/IgnacioCorrecher" class="social" target="_blank" rel="noopener noreferrer" data-astro-cid-dmqpwcec> <span class="sr-only" data-astro-cid-dmqpwcec>GitHub</span> <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><g stroke-linecap="round" stroke-linejoin="round"><path fill="none" stroke-width="14.7" d="M55.7 167.2c13.9 1 21.3 13.1 22.2 14.6 4.2 7.2 10.4 9.6 18.3 7.1l1.1-3.4a60.3 60.3 0 0 1-25.8-11.9c-12-10.1-18-25.6-18-46.3"/><path fill="none" stroke-width="16" d="M61.4 205.1a24.5 24.5 0 0 1-3-6.1c-3.2-7.9-7.1-10.6-7.8-11.1l-1-.6c-2.4-1.6-9.5-6.5-7.2-13.9 1.4-4.5 6-7.2 12.3-7.2h.8c4 .3 7.6 1.5 10.7 3.2-9.1-10.1-13.6-24.3-13.6-42.3 0-11.3 3.5-21.7 10.1-30.4A46.7 46.7 0 0 1 65 67.3a8.3 8.3 0 0 1 5-4.7c2.8-.9 13.3-2.7 33.2 9.9a105 105 0 0 1 50.5 0c19.9-12.6 30.4-10.8 33.2-9.9 2.3.7 4.1 2.4 5 4.7 5 12.7 4 23.2 2.6 29.4 6.7 8.7 10 18.9 10 30.4 0 42.6-25.8 54.7-43.6 58.7 1.4 4.1 2.2 8.8 2.2 13.7l-.1 23.4v2.3"/><path fill="none" stroke-width="16" d="M160.9 185.7c1.4 4.1 2.2 8.8 2.2 13.7l-.1 23.4v2.3A98.6 98.6 0 1 0 61.4 205c-1.4-2.1-11.3-17.5-11.8-17.8-2.4-1.6-9.5-6.5-7.2-13.9 1.4-4.5 6-7.2 12.3-7.2h.8c4 .3 7.6 1.5 10.7 3.2-9.1-10.1-13.6-24.3-13.6-42.3 0-11.3 3.5-21.7 10.1-30.4A46.4 46.4 0 0 1 65 67.3a8.3 8.3 0 0 1 5-4.7c2.8-.9 13.3-2.7 33.2 9.9a105 105 0 0 1 50.5 0c19.9-12.6 30.4-10.8 33.2-9.9 2.3.7 4.1 2.4 5 4.7 5 12.7 4 23.2 2.6 29.4 6.7 8.7 10 18.9 10 30.4.1 42.6-25.8 54.7-43.6 58.6z"/><path fill="none" stroke-width="18.7" d="m170.1 203.3 17.3-12 17.2-18.7 9.5-26.6v-27.9l-9.5-27.5" /><path fill="none" stroke-width="22.7" d="m92.1 57.3 23.3-4.6 18.7-1.4 29.3 5.4m-110 32.6-8 16-4 21.4.6 20.3 3.4 13" /><path fill="none" stroke-width="13.3" d="M28.8 133a100 100 0 0 0 66.9 94.4v-8.7c-22.4 1.8-33-11.5-35.6-19.8-3.4-8.6-7.8-11.4-8.5-11.8"/></g></g>  </svg>  </a> </div> </div> </noscript> <div id="menu-content" hidden data-astro-cid-dmqpwcec> <ul class="nav-items" data-astro-cid-dmqpwcec> <li data-astro-cid-dmqpwcec> <a class="link" href="/" data-astro-cid-dmqpwcec> Home </a> </li><li data-astro-cid-dmqpwcec> <a class="link active" href="/work/" data-astro-cid-dmqpwcec> Work </a> </li><li data-astro-cid-dmqpwcec> <a class="link" href="/about/" data-astro-cid-dmqpwcec> About </a> </li> </ul> <div class="menu-footer" data-astro-cid-dmqpwcec> <div class="socials" data-astro-cid-dmqpwcec> <a href="https://twitter.com/ignacorrecher" class="social" target="_blank" rel="noopener noreferrer" data-astro-cid-dmqpwcec> <span class="sr-only" data-astro-cid-dmqpwcec>Twitter</span> <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M128 88c0-22 18.5-40.3 40.5-40a40 40 0 0 1 36.2 24H240l-32.3 32.3A127.9 127.9 0 0 1 80 224c-32 0-40-12-40-12s32-12 48-36c0 0-64-32-48-120 0 0 40 40 88 48Z"/></g>  </svg>  </a><a href="https://github.com/IgnacioCorrecher" class="social" target="_blank" rel="noopener noreferrer" data-astro-cid-dmqpwcec> <span class="sr-only" data-astro-cid-dmqpwcec>GitHub</span> <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><g stroke-linecap="round" stroke-linejoin="round"><path fill="none" stroke-width="14.7" d="M55.7 167.2c13.9 1 21.3 13.1 22.2 14.6 4.2 7.2 10.4 9.6 18.3 7.1l1.1-3.4a60.3 60.3 0 0 1-25.8-11.9c-12-10.1-18-25.6-18-46.3"/><path fill="none" stroke-width="16" d="M61.4 205.1a24.5 24.5 0 0 1-3-6.1c-3.2-7.9-7.1-10.6-7.8-11.1l-1-.6c-2.4-1.6-9.5-6.5-7.2-13.9 1.4-4.5 6-7.2 12.3-7.2h.8c4 .3 7.6 1.5 10.7 3.2-9.1-10.1-13.6-24.3-13.6-42.3 0-11.3 3.5-21.7 10.1-30.4A46.7 46.7 0 0 1 65 67.3a8.3 8.3 0 0 1 5-4.7c2.8-.9 13.3-2.7 33.2 9.9a105 105 0 0 1 50.5 0c19.9-12.6 30.4-10.8 33.2-9.9 2.3.7 4.1 2.4 5 4.7 5 12.7 4 23.2 2.6 29.4 6.7 8.7 10 18.9 10 30.4 0 42.6-25.8 54.7-43.6 58.7 1.4 4.1 2.2 8.8 2.2 13.7l-.1 23.4v2.3"/><path fill="none" stroke-width="16" d="M160.9 185.7c1.4 4.1 2.2 8.8 2.2 13.7l-.1 23.4v2.3A98.6 98.6 0 1 0 61.4 205c-1.4-2.1-11.3-17.5-11.8-17.8-2.4-1.6-9.5-6.5-7.2-13.9 1.4-4.5 6-7.2 12.3-7.2h.8c4 .3 7.6 1.5 10.7 3.2-9.1-10.1-13.6-24.3-13.6-42.3 0-11.3 3.5-21.7 10.1-30.4A46.4 46.4 0 0 1 65 67.3a8.3 8.3 0 0 1 5-4.7c2.8-.9 13.3-2.7 33.2 9.9a105 105 0 0 1 50.5 0c19.9-12.6 30.4-10.8 33.2-9.9 2.3.7 4.1 2.4 5 4.7 5 12.7 4 23.2 2.6 29.4 6.7 8.7 10 18.9 10 30.4.1 42.6-25.8 54.7-43.6 58.6z"/><path fill="none" stroke-width="18.7" d="m170.1 203.3 17.3-12 17.2-18.7 9.5-26.6v-27.9l-9.5-27.5" /><path fill="none" stroke-width="22.7" d="m92.1 57.3 23.3-4.6 18.7-1.4 29.3 5.4m-110 32.6-8 16-4 21.4.6 20.3 3.4 13" /><path fill="none" stroke-width="13.3" d="M28.8 133a100 100 0 0 0 66.9 94.4v-8.7c-22.4 1.8-33-11.5-35.6-19.8-3.4-8.6-7.8-11.4-8.5-11.8"/></g></g>  </svg>  </a> </div> <div class="theme-toggle" data-astro-cid-dmqpwcec> <theme-toggle data-astro-transition-persist="theme-toggle" data-astro-cid-x3pjskd3> <button data-astro-cid-x3pjskd3> <span class="sr-only" data-astro-cid-x3pjskd3>Dark theme</span> <span class="icon light" data-astro-cid-x3pjskd3><svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><circle cx="128" cy="128" r="60" fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16"/><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M128 36V16M63 63 49 49m-13 79H16m47 65-14 14m79 13v20m65-47 14 14m13-79h20m-47-65 14-14"/></g>  </svg> </span> <span class="icon dark" data-astro-cid-x3pjskd3><svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M216 112V64m24 24h-48m-24-64v32m16-16h-32m65 113A92 92 0 0 1 103 39h0a92 92 0 1 0 114 114Z"/></g>  </svg> </span> </button> </theme-toggle>   </div> </div> </div> </nav>    <div class="stack gap-20" data-astro-cid-qwekciqp> <div class="stack gap-15" data-astro-cid-qwekciqp> <header data-astro-cid-qwekciqp> <div class="wrapper stack gap-2" data-astro-cid-qwekciqp> <a class="back-link" href="/work/" data-astro-cid-qwekciqp><svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M216 128H40m72-72-72 72 72 72"/></g>  </svg>  Work</a> <div class="hero stack gap-4 start" data-astro-cid-bbe6dxrz> <div class="stack gap-2" data-astro-cid-bbe6dxrz> <h1 class="title" data-astro-cid-bbe6dxrz>nanoGPT x Friends</h1>  </div>  <div class="project-info" data-astro-cid-qwekciqp> <div class="left-column" data-astro-cid-qwekciqp> <div class="tags" data-astro-cid-qwekciqp> <div class="pill" data-astro-cid-2qeywk4b>Data Cleaning</div> <div class="pill" data-astro-cid-2qeywk4b>Visualization</div> <div class="pill" data-astro-cid-2qeywk4b>Machine Leaning</div> <div class="pill" data-astro-cid-2qeywk4b>R</div>  </div> <p class="description" style="padding-top: 30px; padding-right:15px; text-align: justify;" data-astro-cid-qwekciqp>This project showcases a unique implementation of the Transformer architecture, inspired by the &quot;Attention is All You Need&quot; paper and Andrej Karpathy&#39;s tutorial series.
</p> </div> <div class="right-column" data-astro-cid-qwekciqp> <div class="github-card" data-astro-cid-cmjzrqcb> <div class="header" data-astro-cid-cmjzrqcb> <img src="https://avatars.githubusercontent.com/u/52128969?v=4" alt="IgnacioCorrecher" class="avatar" data-astro-cid-cmjzrqcb> <h3 data-astro-cid-cmjzrqcb><a href="https://github.com/IgnacioCorrecher/nanoGPTxFRIENDS" target="_blank" rel="noopener noreferrer" data-astro-cid-cmjzrqcb>IgnacioCorrecher/nanoGPTxFRIENDS</a></h3> </div> <p class="description" data-astro-cid-cmjzrqcb></p> <div class="stats" data-astro-cid-cmjzrqcb> <div class="stat" data-astro-cid-cmjzrqcb> <span class="stat-icon" data-astro-cid-cmjzrqcb>⭐</span> <span data-astro-cid-cmjzrqcb>0 stars</span> </div> <div class="stat" data-astro-cid-cmjzrqcb> <span class="stat-icon" data-astro-cid-cmjzrqcb>👀</span> <span data-astro-cid-cmjzrqcb>0 watchers</span> </div> <div class="stat" data-astro-cid-cmjzrqcb> <span class="stat-icon" data-astro-cid-cmjzrqcb>📝</span> <span data-astro-cid-cmjzrqcb>4 commits</span> </div> </div> <div class="language" data-astro-cid-cmjzrqcb> <span class="language-dot" style="background-color: #f1e05a;" data-astro-cid-cmjzrqcb></span> <span data-astro-cid-cmjzrqcb>Jupyter Notebook</span> </div> </div>  </div> </div>  </div>  </div> </header> <main class="wrapper" data-astro-cid-qwekciqp> <div class="stack gap-10 content" data-astro-cid-qwekciqp> <img src="/assets/projects/nanoGPTxFriends/header.webp" alt="Friends Logo" data-astro-cid-qwekciqp> <div class="content" data-astro-cid-qwekciqp> <h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#dataset">Dataset</a></li>
<li><a href="#model-architecture">Model Architecture</a></li>
<li><a href="#nanogpt-model-explanation">nanoGPT Model Explanation</a></li>
<li><a href="#results">Results</a></li>
<li><a href="#acknowledgements">Acknowledgements</a></li>
</ol>
<h2 id="introduction">Introduction</h2>
<p>This project is an exploration of the Transformer model, specifically focusing on its application in natural language generation. By training a nanoGPT model on the Friends TV Show Script dataset, we aim to create new, realistic episodes that capture the essence of the original show.</p>
<h2 id="dataset">Dataset</h2>
<p>The Friends TV Show Script dataset, sourced from Kaggle, contains scripts from all 10 seasons of the show. This dataset is essential for training the model to generate dialogues that reflect the characters’ personalities and the show’s humor.</p>
<h2 id="model-architecture">Model Architecture</h2>
<p>The nanoGPT model mirrors the original Transformer architecture, consisting of multiple layers of encoder-decoder structures. Key features include:</p>
<ul>
<li>Multi-Head Self-Attention Mechanism</li>
<li>Positional Encoding</li>
<li>Feed-Forward Neural Networks</li>
<li>Layer Normalization and Dropout</li>
</ul>
<h2 id="nanogpt-model-explanation">nanoGPT Model Explanation</h2>
<p>This script implements a simplified version of the GPT (Generative Pre-trained Transformer) model using PyTorch. It is designed to generate text based on the “Friends” TV show transcripts. Below is a detailed explanation of each part of the script.</p>
<h3 id="hyperparameters">Hyperparameters</h3>
<p>The script starts by defining several key hyperparameters:</p>
<ul>
<li><strong>Context Length</strong>: This parameter defines the number of tokens the model considers simultaneously during training, which is also known as the block size.</li>
<li><strong>Batch Size</strong>: The number of independent sequences processed in parallel during each iteration of training.</li>
<li><strong>Max Iterations</strong>: The total number of training iterations.</li>
<li><strong>Evaluation Interval</strong>: The frequency at which the model is evaluated on the validation dataset.</li>
<li><strong>Learning Rate</strong>: The rate at which the model’s weights are updated during training.</li>
<li><strong>Device</strong>: The script checks whether a GPU is available and uses it if possible; otherwise, it defaults to the CPU.</li>
<li><strong>Embedding Dimension</strong>: The size of the embedding vector that represents each token.</li>
<li><strong>Number of Attention Heads</strong>: This defines how many separate attention mechanisms are used in the multi-head attention block.</li>
<li><strong>Number of Layers</strong>: The total number of layers in the Transformer model.</li>
<li><strong>Dropout Rate</strong>: A technique used to prevent overfitting by randomly setting a fraction of the input units to zero during training.</li>
</ul>
<h3 id="data-preparation">Data Preparation</h3>
<p>The script reads the “Friends” TV show transcript from a text file and processes it to create a vocabulary of unique characters. This vocabulary is then used to convert the text into a sequence of numerical indices, where each index corresponds to a character in the vocabulary.</p>
<p>Two dictionaries are created: one that maps characters to indices and another that maps indices back to characters. These dictionaries are used to encode strings into numerical sequences and decode numerical sequences back into strings.</p>
<h3 id="train-test-split">Train-Test Split</h3>
<p>The entire dataset is divided into training and testing sets, with 95% of the data used for training and the remaining 5% for testing. This split ensures that the model is trained on a large portion of the data while still having a separate set for evaluation.</p>
<h3 id="data-batching">Data Batching</h3>
<p>To efficiently train the model, the script includes a function that generates batches of data. Each batch consists of sequences of tokens (input) and the corresponding sequences shifted by one position (target). The model learns to predict the next token in the sequence.</p>
<h3 id="loss-estimation">Loss Estimation</h3>
<p>The script includes a method for evaluating the model’s performance. During evaluation, the model’s predictions are compared against the actual sequences, and the average loss is calculated. This loss estimation helps monitor the model’s performance on both the training and validation datasets.</p>
<h3 id="model-architecture-1">Model Architecture</h3>
<p>The core of the script is the implementation of the nanoGPT model, which includes several key components:</p>
<ul>
<li><strong>Multi-Head Self-Attention</strong>: This mechanism allows the model to focus on different parts of the input sequence when making predictions. The multi-head setup means the model can attend to multiple positions in the sequence simultaneously, which improves its ability to capture complex relationships in the data.</li>
<li><strong>Feed-Forward Neural Networks</strong>: After the attention mechanism processes the input, the data is passed through a series of fully connected layers. These layers help the model transform the input into a more useful representation for predicting the next token.</li>
<li><strong>Positional Embeddings</strong>: Since Transformers do not inherently understand the order of tokens in a sequence, positional embeddings are added to the input embeddings to provide the model with information about the position of each token.</li>
<li><strong>Layer Normalization and Dropout</strong>: These techniques are used to stabilize and regularize the training process, making the model more robust and reducing the likelihood of overfitting.</li>
</ul>
<h3 id="training-loop">Training Loop</h3>
<p>The model is trained over a specified number of iterations. During each iteration, the script:</p>
<ol>
<li><strong>Evaluates</strong> the model at set intervals to monitor progress.</li>
<li><strong>Generates Batches</strong> of training data.</li>
<li><strong>Computes Loss</strong>: The difference between the model’s predictions and the actual sequences is calculated.</li>
<li><strong>Backpropagation</strong>: The model’s weights are updated to minimize the loss using the AdamW optimizer.</li>
<li><strong>Generates Text</strong>: After training, the model can generate new sequences of text by predicting one token at a time, starting from an initial context.</li>
</ol>
<h3 id="text-generation">Text Generation</h3>
<p>Finally, the script includes a method for generating text using the trained model. Given an initial context (e.g., the first token or a few tokens), the model predicts the next token, appends it to the context, and repeats the process. This iterative generation continues until the desired length of text is achieved. The generated text is then saved to a file.</p>
<p>Overall, this script provides a practical implementation of a small-scale GPT model capable of learning from and generating text similar to the “Friends” TV show transcripts.</p>
<h2 id="results">Results</h2>
<p>Here you can find an example of the generated output by the model:</p>
<embed src="/assets/projects/nanoGPTxFriends/output.txt" type="application/pdf" width="100%" height="300px">
<h2 id="acknowledgements">Acknowledgements</h2>
<p>This project was inspired by:</p>
<ul>
<li><a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a> by Vaswani et al.</li>
<li><a href="https://www.youtube.com/channel/UC6e2mP01ZLH_kbAyeazCNdg">Andrej Karpathy’s YouTube series</a></li>
<li><a href="https://www.kaggle.com/datasets/rezaghari/friends-series-dataset">Friends TV Show Script dataset</a></li>
</ul> </div> </div> </main> </div> <aside data-astro-cid-rcdzuq3a> <h2 data-astro-cid-rcdzuq3a>Interested in working together?</h2> <a href="mailto:ignaciocorrecher@hotmail.com" data-astro-cid-balv45lp>
Send Me a Message
<svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" style="--size:1.2em" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M210.3 35.9 23.9 88.4a8 8 0 0 0-1.2 15l85.6 40.5a7.8 7.8 0 0 1 3.8 3.8l40.5 85.6a8 8 0 0 0 15-1.2l52.5-186.4a7.9 7.9 0 0 0-9.8-9.8Zm-99.4 109.2 45.2-45.2"/></g>  </svg>  </a>  </aside>  </div>  <footer data-astro-cid-sz7xmlte> <div class="group" data-astro-cid-sz7xmlte> <p data-astro-cid-sz7xmlte>
Designed & Developed in Valencia with <a href="https://astro.build/" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte>Astro</a> <svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 256 256" aria-hidden="true" stroke="currentcolor" fill="currentcolor" style="--size:1.2em" class="astro-patnjmll" data-astro-cid-patnjmll> <g data-astro-cid-patnjmll><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M94.1 184.6c-11.4 33.9-56.6 33.9-56.6 33.9s0-45.2 33.9-56.6m124.5-56.5L128 173.3 82.7 128l67.9-67.9C176.3 34.4 202 34.7 213 36.3a7.8 7.8 0 0 1 6.7 6.7c1.6 11 1.9 36.7-23.8 62.4Z"/><path fill="none" stroke-linecap="round" stroke-linejoin="round" stroke-width="16" d="M184.6 116.7v64.6a8 8 0 0 1-2.4 5.6l-32.3 32.4a8 8 0 0 1-13.5-4.1l-8.4-41.9m11.3-101.9H74.7a8 8 0 0 0-5.6 2.4l-32.4 32.3a8 8 0 0 0 4.1 13.5l41.9 8.4"/></g>  </svg>  </p> <p data-astro-cid-sz7xmlte>&copy; 2024 Ignacio Correcher</p> </div> <p class="socials" data-astro-cid-sz7xmlte> <a href="https://twitter.com/ignacorrecher" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> Twitter</a> <a href="https://github.com/IgnacioCorrecher" target="_blank" rel="noopener noreferrer" data-astro-cid-sz7xmlte> GitHub</a> </p> </footer>  </div>   </body> </html> 